{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from __future__ import division\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rcParams['figure.dpi'] = 2.5 * matplotlib.rcParams['figure.dpi']\n",
    "\n",
    "import numpy as np\n",
    "from scipy import special as ss\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T22:36:03.855885Z",
     "start_time": "2018-06-19T22:36:03.703751Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import george\n",
    "import george.kernels as kernels\n",
    "import emcee\n",
    "from chainconsumer import ChainConsumer\n",
    "import pyDOE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T23:02:58.484916Z",
     "start_time": "2018-06-19T23:02:58.189558Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from model import dataCompress\n",
    "from model import model\n",
    "from model import gproc\n",
    "from model import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolation of known, analytic distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the postulated distribution of binary spin-alignments from Talbot & Thrane (2017), [arXiv:1704.08370](https://arxiv.org/abs/1704.08370). Rather than consider the usual $\\chi_\\mathrm{eff}$ and $\\chi_\\mathrm{p}$ parameters, in the authors' model the observed quantities are assumed to be the projection of each binary component's spin projection onto the orbital angular momentum vector, such that: $$z_1 = \\hat{L}\\cdot\\hat{S}_1, \\\\ z_2 = \\hat{L}\\cdot\\hat{S}_2,$$ where $z_{\\{1,2\\}} \\in [-1,1]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dynamical capture mechanisms in a globular cluster are assumed to produce an isotropic distribution of spin alignments, such that $$p_0(z_1,z_2)=\\frac{1}{4}.$$ For field binaries, the evolutionary path of each progenitor star, along with BH natal kicks during supernovae, is assumed to produce a truncated Gaussian distribution of alignments. A hyperparameter controls the degree with which (anti-)alignment is favored. Thus, $$p_1(z_1,z_2) = \\frac{2}{\\pi}\\frac{1}{\\sigma_1}\\frac{e^{-(z_1-1)^2 / 2\\sigma_1^2}}{\\mathrm{erf}(\\sqrt{2}\\sigma_1)} \\frac{1}{\\sigma_2}\\frac{e^{-(z_2-1)^2 / 2\\sigma_2^2}}{\\mathrm{erf}(\\sqrt{2}\\sigma_2)}.$$ In this model, $\\sigma=0$ produces perfect alignment, while $\\sigma=\\infty$ tends to the dynamic-capture distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T22:36:09.235498Z",
     "start_time": "2018-06-19T22:36:09.175390Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Defining all the functions mentioned above from Talbot & Thrane\n",
    "\n",
    "def gauss_trunc(x,sigma):\n",
    "    '''Truncated Gaussian distribution'''\n",
    "    return ( np.sqrt(2.0 / np.pi) * (1.0 / sigma) * \\\n",
    "            np.exp(-0.5 * (x-1.0)**2.0 / sigma**2.0) / ss.erf(np.sqrt(2.0) * sigma) )\n",
    "\n",
    "def gauss_full(x,sigma):\n",
    "    '''Gaussian distribution'''\n",
    "    return ( np.sqrt(2.0 / np.pi) * (1.0 / sigma) * \\\n",
    "            np.exp(-0.5 * (x-1.0)**2.0 / sigma**2.0))\n",
    "\n",
    "def gauss_fullprod(x1,x2,sigma1,sigma2):\n",
    "    '''Product of Gaussian pdfs'''\n",
    "    return gauss_full(x1,sigma1) * gauss_full(x2,sigma2)\n",
    "\n",
    "def p0(z1, z2):\n",
    "    '''Dynamic-capture isotropic distribution of spin alignments.'''\n",
    "    if z1.shape != z2.shape:\n",
    "        return 'Error! Your population vectors have unequal lengths'\n",
    "    else:\n",
    "        return 0.25 * np.ones(z1.shape)\n",
    "\n",
    "def p1(z1, z2, sigma1, sigma2):\n",
    "    '''Field binary distribution of spin alignments'''\n",
    "    if z1.shape != z2.shape:\n",
    "        return 'Error! Your population vectors have unequal lengths'\n",
    "    else:\n",
    "        return gauss_trunc(z1, sigma1) * gauss_trunc(z2, sigma2)\n",
    "\n",
    "def p(z1, z2, sigma1, sigma2, xi):\n",
    "    '''Total population distribution of spin alignments as dynamical/field mixture'''\n",
    "    return (1.0-xi) * p0(z1, z2) + xi * p1(z1, z2, sigma1, sigma2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D compression test in sigma space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T22:36:11.222235Z",
     "start_time": "2018-06-19T22:36:11.174029Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class sampleTrans2d(object):\n",
    "    \"\"\"Sampling tranformations for sigma\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def unit2range(self, x):\n",
    "        return 10.0**(-1.0 + (1.0 - (-1.0)) * x)\n",
    "    \n",
    "    def range2unit(self, y):\n",
    "        return (1.0 + np.log10(y)) / 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T22:36:18.526395Z",
     "start_time": "2018-06-19T22:36:18.480068Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining bins in parameter space.\n",
    "\n",
    "z1edges = np.linspace(-1.0, 1.0, 40)\n",
    "z2edges = np.linspace(-1.0, 1.0, 40)\n",
    "\n",
    "z1m = (z1edges[1:] + z1edges[:-1]) / 2.0\n",
    "z2m = (z2edges[1:] + z2edges[:-1]) / 2.0\n",
    "\n",
    "# Sort data in 2-d space of z1 and z2 into one long vector\n",
    "\n",
    "z1v, z2v  = np.meshgrid(z1m, z2m, indexing='ij')\n",
    "z_sample = np.zeros((np.prod(z1v.shape),2))\n",
    "\n",
    "z_sample[:,0] = z1v.flatten()\n",
    "z_sample[:,1] = z2v.flatten() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T22:36:25.265335Z",
     "start_time": "2018-06-19T22:36:25.121734Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Also, define the sigma values (really, any parameters of interest) at which simulations are run.\n",
    "## We will try to emulate the truncated Gaussian distribution.\n",
    "\n",
    "nsims = 100\n",
    "ndim = 2\n",
    "\n",
    "## latin hypercube sampling\n",
    "## consider on range [0,1]\n",
    "sigma_sample = pyDOE.lhs(n=ndim, samples=nsims, criterion='centermaximin')\n",
    "\n",
    "smat = np.zeros((z_sample.shape[0], nsims))\n",
    "print smat.shape\n",
    "strans = sampleTrans2d() # instantiate class for sampling transformation\n",
    "for ii,sig in enumerate(sigma_sample):\n",
    "    smat[:,ii] = np.outer(gauss_trunc(z1m,strans.unit2range(sig[0])), \n",
    "                          gauss_trunc(z2m,strans.unit2range(sig[1]))).flatten() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T22:36:28.045235Z",
     "start_time": "2018-06-19T22:36:27.976932Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datComp = dataCompress.dataCompress(dataMat = np.log10(smat), \n",
    "                                    histBins = None,\n",
    "                                    simDesign = strans.unit2range(sigma_sample), tol=1e-5)\n",
    "\n",
    "datComp.unitTrans()\n",
    "datComp.basisCompute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T22:36:28.668021Z",
     "start_time": "2018-06-19T22:36:28.628209Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datComp.pca_basis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T22:36:31.084751Z",
     "start_time": "2018-06-19T22:36:30.109831Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## NOTE: This is the correct ordering of axes in the flattening scheme.\n",
    "\n",
    "print strans.unit2range(sigma_sample[23])\n",
    "test = 10.0**datComp.rotate2full(datComp.pca_weights[:,23]).reshape((z1m.shape[0], z2m.shape[0]))\n",
    "test = np.abs(test)\n",
    "\n",
    "plt.imshow(test,\n",
    "           origin='lower', aspect='auto',\n",
    "           cmap='viridis_r', extent=[z2edges[0], z2edges[-1], \n",
    "                                     z1edges[0], z1edges[-1]])\n",
    "plt.xlabel('$z_2$')\n",
    "plt.ylabel('$z_1$')\n",
    "cb = plt.colorbar()\n",
    "cb.set_label(\"PDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T22:36:36.468882Z",
     "start_time": "2018-06-19T22:36:36.423219Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "match_compare = []\n",
    "match_compare.append(datComp.match())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T22:36:37.377014Z",
     "start_time": "2018-06-19T22:36:36.823457Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(1.0-match_compare[0], alpha=0.6,)\n",
    "plt.minorticks_on()\n",
    "plt.tick_params(which='both',direction='in',tick2On=True)\n",
    "plt.xlabel('Training simulation')\n",
    "plt.ylabel(r'$1-$Match')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA GP interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T22:36:43.463614Z",
     "start_time": "2018-06-19T22:36:43.412359Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instanciate a list of GP kernels and models [one for each distribution basis function]\n",
    "\n",
    "gp_george = [None for _ in range(datComp.dim)]\n",
    "k = []\n",
    "\n",
    "for ii in range(datComp.dim):\n",
    "    gp_george[ii] = gproc.gp(x = strans.range2unit(datComp.simDesign), \n",
    "                             y = datComp.pca_weights[ii,:], yerr = 1e-10,\n",
    "                             p0 = np.log10(3.0*np.ones(datComp.simDesign.shape[1]+1)),\n",
    "                             pmin = -10.0*np.ones(datComp.simDesign.shape[1]+1),\n",
    "                             pmax = 10.0*np.ones(datComp.simDesign.shape[1]+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T22:39:13.830364Z",
     "start_time": "2018-06-19T22:36:46.691532Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sample the posterior distribution of the kernel parameters \n",
    "# to find MAP value for each basis function\n",
    "\n",
    "sampler = [None for _ in range(datComp.dim)]\n",
    "for ii in range(datComp.dim):\n",
    "    # Set up the sampler.\n",
    "    nwalkers, ndim = 36, datComp.simDesign.shape[1]+1\n",
    "    sampler[ii] = emcee.EnsembleSampler(nwalkers, ndim, gp_george[ii].lnprob)\n",
    "\n",
    "    # Initialize the walkers.\n",
    "    p0 = [gp_george[ii].p0 + 1e-1 * np.random.randn(ndim)\n",
    "          for i in range(nwalkers)]\n",
    "\n",
    "    print ii, \"Running burn-in\"\n",
    "    p0, lnp, _ = sampler[ii].run_mcmc(p0, 500)\n",
    "    sampler[ii].reset()\n",
    "\n",
    "    print ii, \"Running second burn-in\"\n",
    "    p = p0[np.argmax(lnp)]\n",
    "    p0 = [p + 1e-1 * np.random.randn(ndim) for i in xrange(nwalkers)]\n",
    "    p0, _, _ = sampler[ii].run_mcmc(p0, 500)\n",
    "    sampler[ii].reset()\n",
    "\n",
    "    print ii, \"Running production\", '\\n'\n",
    "    p0, _, _ = sampler[ii].run_mcmc(p0, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T22:39:16.572623Z",
     "start_time": "2018-06-19T22:39:16.526340Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Populate the GP class with the details of the kernel \n",
    "## MAP values for each frequency.\n",
    "for ii in range(datComp.dim):\n",
    "    gp_george[ii].emcee_kernel_map = sampler[ii].flatchain[np.argmax(sampler[ii].flatlnprobability)] \n",
    "    gp_george[ii].emcee_flatchain = sampler[ii].flatchain \n",
    "    print ii, gp_george[ii].emcee_kernel_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T22:39:19.840844Z",
     "start_time": "2018-06-19T22:39:19.792845Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gpnew = []\n",
    "for ii in range(datComp.dim):\n",
    "    # Let's grab the MAP values\n",
    "    mapparams = 10.0**sampler[ii].flatchain[np.argmax(sampler[ii].flatlnprobability)]  \n",
    "    # Set up a GP kernel with the MAP values found from the sampling.\n",
    "    k = mapparams[0] * kernels.ExpSquaredKernel(mapparams[1:],ndim=len(mapparams[1:]))\n",
    "    # Instanciate the GP.\n",
    "    gpnew.append(george.GP(k))\n",
    "    # Pre-compute the factorization of the matrix.\n",
    "    gpnew[ii].compute(strans.range2unit(datComp.simDesign), 1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T22:39:35.932731Z",
     "start_time": "2018-06-19T22:39:35.889928Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reconstruct parameter distribution from GP interpolants\n",
    "\n",
    "def construct_pdf(coord, datComp, strans, gp):\n",
    "    pdf = 10.0**datComp.rotate2full(np.array([gp[jj].predict(datComp.pca_weights[jj,:],\n",
    "                                                       strans.range2unit(np.atleast_2d(coord)))[0][0]\n",
    "                                               for jj in range(len(gp))]))\n",
    "    pdf = np.abs(pdf)\n",
    "    pdf = pdf - np.min(pdf)\n",
    "    #pdf /= np.sum(pdf * np.outer(np.diff(z1), np.diff(z2)).flatten())\n",
    "    return pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T22:39:36.753715Z",
     "start_time": "2018-06-19T22:39:36.110125Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(construct_pdf(np.array([0.45,0.45]), datComp, strans, gpnew).reshape((z1m.shape[0], z2m.shape[0])),\n",
    "           origin='lower', aspect='auto',\n",
    "           cmap='viridis_r', extent=[z2edges[0], z2edges[-1], \n",
    "                                     z1edges[0], z1edges[-1]])\n",
    "cb = plt.colorbar()\n",
    "cb.set_label(\"PDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T22:39:41.486999Z",
     "start_time": "2018-06-19T22:39:40.882296Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the analytic parameter distribution\n",
    "\n",
    "test_against = np.outer(gauss_trunc(z1m,0.45), \n",
    "                        gauss_trunc(z2m,0.45)).flatten()\n",
    "\n",
    "plt.imshow(test_against.reshape((z1m.shape[0], z2m.shape[0])),\n",
    "           origin='lower', aspect='auto',\n",
    "           cmap='viridis_r', extent=[z2edges[0], z2edges[-1], \n",
    "                                     z1edges[0], z1edges[-1]])\n",
    "cb = plt.colorbar()\n",
    "cb.set_label(\"PDF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCMC on Test Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T23:03:05.212898Z",
     "start_time": "2018-06-19T23:03:05.167137Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load in a test population\n",
    "\n",
    "pop = np.load('./test_pop.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T23:03:05.335486Z",
     "start_time": "2018-06-19T23:03:05.292670Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a simple model\n",
    "\n",
    "simple1d_model = model.model(data=pop, x=[z1edges,z2edges], interp=gpnew, sampTrans=strans, dataComp=datComp, \n",
    "                             pmin=np.log10(np.array([0.1,0.1])), pmax=np.log10(np.array([10.,10.])),\n",
    "                             yerr=None,\n",
    "                             interpType='gp1d', interpScale='log10',\n",
    "                             interpErrors=True, interpHyperErrors=True, \n",
    "                             catalogType='median',analytic=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T23:03:05.935223Z",
     "start_time": "2018-06-19T23:03:05.893901Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filling in GP interpolant hyperparameter properties\n",
    "simple1d_model.gp_kernel_map = [g.emcee_kernel_map for g in gp_george]\n",
    "simple1d_model.gp_kernel_posterior = [g.emcee_flatchain for g in gp_george]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T23:12:07.227009Z",
     "start_time": "2018-06-19T23:03:06.820414Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use emcee to sample the hyper-parameter posterior distribution\n",
    "\n",
    "nwalkers, ndim = 36, 2\n",
    "sampler_simple = emcee.EnsembleSampler(nwalkers, ndim, simple1d_model.lnprob)\n",
    "\n",
    "# Initialize the walkers.\n",
    "p0 = [np.log10([3.0,3.0]) + 1e-2 * np.random.randn(ndim)\n",
    "      for i in range(nwalkers)]\n",
    "\n",
    "print \"Running burn-in\"\n",
    "p0, lnp, _ = sampler_simple.run_mcmc(p0, 500)\n",
    "sampler_simple.reset()\n",
    "\n",
    "print \"Running second burn-in\"\n",
    "p = p0[np.argmax(lnp)]\n",
    "p0 = [p + 1e-2 * np.random.randn(ndim) for i in xrange(nwalkers)]\n",
    "p0, _, _ = sampler_simple.run_mcmc(p0, 500)\n",
    "sampler_simple.reset()\n",
    "\n",
    "print \"Running production\"\n",
    "p0, _, _ = sampler_simple.run_mcmc(p0, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T23:12:32.415391Z",
     "start_time": "2018-06-19T23:12:31.626483Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(10.0**sampler_simple.flatchain[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T23:12:38.233823Z",
     "start_time": "2018-06-19T23:12:38.190618Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the analytic model\n",
    "\n",
    "analytic_model = model.model(data=pop, x=[z1edges,z2edges], interp=gpnew, sampTrans=strans, dataComp=datComp, \n",
    "                             pmin=np.log10(np.array([0.1,0.1])), pmax=np.log10(np.array([10.,10.])),\n",
    "                             interpType='gp1d', interpScale='log10',\n",
    "                             interpErrors=False, interpHyperErrors=False, \n",
    "                             catalogType='median',  \n",
    "                             yerr=None, analytic=gauss_fullprod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T23:12:41.596902Z",
     "start_time": "2018-06-19T23:12:38.492895Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use emcee to sample the hyper-parameter posterior distribution \n",
    "# (in the analytic model)\n",
    "\n",
    "nwalkers, ndim = 36, 2\n",
    "sampler_analytic = emcee.EnsembleSampler(nwalkers, ndim, analytic_model.lnprob)\n",
    "\n",
    "# Initialize the walkers.\n",
    "p0 = [np.log10([3.0,3.0]) + 1e-2 * np.random.randn(ndim)\n",
    "      for i in range(nwalkers)]\n",
    "\n",
    "print \"Running burn-in\"\n",
    "p0, lnp, _ = sampler_analytic.run_mcmc(p0, 500)\n",
    "sampler_analytic.reset()\n",
    "\n",
    "print \"Running second burn-in\"\n",
    "p = p0[np.argmax(lnp)]\n",
    "p0 = [p + 1e-2 * np.random.randn(ndim) for i in xrange(nwalkers)]\n",
    "p0, _, _ = sampler_analytic.run_mcmc(p0, 500)\n",
    "sampler_analytic.reset()\n",
    "\n",
    "print \"Running production\"\n",
    "p0, _, _ = sampler_analytic.run_mcmc(p0, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T23:13:01.052545Z",
     "start_time": "2018-06-19T23:12:55.122826Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compare the analytic model with the GP-emulator model\n",
    "\n",
    "c = ChainConsumer()\n",
    "c.add_chain(10.0**sampler_simple.flatchain, \n",
    "            parameters=[r'$\\sigma_1$', r'$\\sigma_2$'], \n",
    "            name='GP model')\n",
    "c.add_chain(10.0**sampler_analytic.flatchain, \n",
    "            parameters=[r'$\\sigma_1$', r'$\\sigma_2$'], \n",
    "            name='Analytic model')\n",
    "c.configure(sigma2d=False, spacing=0., shade_alpha=0.35, \n",
    "            colors=['#1f77b4', '#d62728'], legend_kwargs=dict(prop={'size':8}))\n",
    "c.configure_truth(linestyle='dashed',color='w',alpha=1.0,linewidth=1.3)\n",
    "fig = c.plotter.plot(figsize=\"column\", truth=[0.45,0.45])\n",
    "fig.set_size_inches(3.0,3.0)  \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "743px",
    "left": "0px",
    "right": "1458px",
    "top": "107px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
